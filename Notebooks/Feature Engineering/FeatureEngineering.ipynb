{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4471,
     "status": "ok",
     "timestamp": 1581450180951,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "6-wm7rJQJ4DK",
    "outputId": "ef9f4091-1ef8-4c4b-d3bc-fe57709461a6"
   },
   "outputs": [],
   "source": [
    "# !pip install nlp_primitives\n",
    "# !pip install bs4\n",
    "# !pip install spacy\n",
    "# !pip install gensim\n",
    "# !pip install nltk\n",
    "# !pip install seaborn\n",
    "# ! python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7506,
     "status": "ok",
     "timestamp": 1581450184014,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "Hev0IrSbFCVU",
    "outputId": "5f04254e-5f9d-400c-b3a8-eeba60d9a82b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7490,
     "status": "ok",
     "timestamp": 1581450184016,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "sZGQZ546O_KN",
    "outputId": "1446bb1b-e198-4c8e-b6bb-905221cf27f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import gensim as gen\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "from featuretools.primitives import  AggregationPrimitive\n",
    "from nlp_primitives import (\n",
    "    DiversityScore,\n",
    "    LSA,\n",
    "    MeanCharactersPerWord,\n",
    "    PolarityScore, \n",
    "    UniversalSentenceEncoder,\n",
    "    PunctuationCount,\n",
    "    StopwordCount,\n",
    "    TitleWordCount,\n",
    "    UpperCaseCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQnfLUt2PHQ3"
   },
   "outputs": [],
   "source": [
    "AMBIGUOUS_WORDS_URL = 'https://muse.dillfrog.com/lists/ambiguous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNwI7DBTD1Le"
   },
   "source": [
    "Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qwhzSceD3wO"
   },
   "outputs": [],
   "source": [
    "# yaniv\n",
    "# path = \"/content/drive/My Drive/Final Project (Personal)/\"\n",
    "\n",
    "# avi\n",
    "# path = \"/content/drive/My Drive/DataScientistITCAvi/Final_Project/Model/Notebooks/\"\n",
    "\n",
    "# cnvrg\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8mqQiOUQ9Fa"
   },
   "source": [
    "Load Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0H5IyCGPe7F"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path+'eda_reddit_jokes.pkl')[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7755,
     "status": "ok",
     "timestamp": 1581450184317,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "nH1p4PeRQVB-",
    "outputId": "aca32ac4-efc4-440f-a0d9-38db2cba5703"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate how you cant even say black paint anymo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian raises his hand and says, “He’s in Heave...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I walked into a PETA adoption center and the r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remember when you were a kid and when you crie...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My boss said to me, \"you're the worst train dr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                joke  score\n",
       "0  I hate how you cant even say black paint anymo...      1\n",
       "1  Brian raises his hand and says, “He’s in Heave...      1\n",
       "2  I walked into a PETA adoption center and the r...      1\n",
       "3  Remember when you were a kid and when you crie...     15\n",
       "4  My boss said to me, \"you're the worst train dr...      3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z83AdZRSlWPR"
   },
   "source": [
    "Load Gensim word embedddings (Google news negative) - Need to check if there's a better embedding to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gB78msGALJS"
   },
   "outputs": [],
   "source": [
    "# model_embeddings = gen.models.KeyedVectors.load_word2vec_format(path+'GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDBqx1LjQsPX"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "def en_tokenize(string):\n",
    "    return nlp(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K4eQBeozlqq8"
   },
   "source": [
    "Add ambiguous words counter features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1jrqIpwg3z_"
   },
   "outputs": [],
   "source": [
    "def get_ambiguous_words():\n",
    "  res = requests.get(AMBIGUOUS_WORDS_URL)\n",
    "  page_soup = BeautifulSoup(res.content)\n",
    "  a_tags = page_soup.find_all('a', href=re.compile(r'.*/meaning/word/*'))\n",
    "  ambiguous_words = [word.text for word in a_tags]\n",
    "  return ambiguous_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19606,
     "status": "ok",
     "timestamp": 1581450196199,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "cxQuL0deSK_q",
    "outputId": "46ef4d23-eb49-46ee-d0c2-b6b87ca64aa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    7\n",
       "2    3\n",
       "3    2\n",
       "4    1\n",
       "Name: ambiguous_words, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous_words = get_ambiguous_words()\n",
    "df['ambiguous_words'] = df['joke'].apply(lambda x: sum([str(w) in ambiguous_words for w in x]))\n",
    "df['ambiguous_words'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nmk_0YHwSnz1"
   },
   "source": [
    "Repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hrkt3fy8KRP3"
   },
   "outputs": [],
   "source": [
    "spacy_col = df['joke'].apply(en_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNX1SzbZSmdn"
   },
   "outputs": [],
   "source": [
    "token_pos = spacy_col.apply(lambda x: [(elm.text, elm.pos_) for elm in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 130403,
     "status": "ok",
     "timestamp": 1581450307023,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "zgzp6GjbSmdt",
    "outputId": "4ecdc668-6ea7-4fb9-ede5-ad98806f2c7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "b = Word2Vec(brown.sents())\n",
    "\n",
    "def find_best_similarity(string):\n",
    "    \"\"\" find the max similarity between two words \"\"\"\n",
    "    # unique words:\n",
    "    word_list = list(set([word_pos[0] for word_pos in string if word_pos[1] != \"PROPN\"]))\n",
    "    all_combi = list(itertools.combinations(word_list, 2))\n",
    "\n",
    "    max_similarity = 0\n",
    "    for pairs in all_combi:\n",
    "        try:\n",
    "            temp_similatity = b.similarity(pairs[0], pairs[1])\n",
    "            if temp_similatity > max_similarity:\n",
    "                max_similarity = temp_similatity\n",
    "        except:\n",
    "            pass # don't found the word in word2vec\n",
    "    return max_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 320147,
     "status": "ok",
     "timestamp": 1581450496780,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "GJ-CwQbvSmdz",
    "outputId": "3bc34c20-b1dd-4bef-eb3e-7e331f176db1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df['best_score_similarity_words'] = token_pos.apply(find_best_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 320141,
     "status": "ok",
     "timestamp": 1581450496787,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "sEcXIzI3Smd3",
    "outputId": "23ef1542-27af-4a10-e020-2f0d92590975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.919720\n",
       "1    0.945242\n",
       "2    0.932165\n",
       "3    0.912641\n",
       "4    0.914353\n",
       "Name: best_score_similarity_words, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['best_score_similarity_words'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lK-zfXKAbg6m"
   },
   "source": [
    "Antoym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nrzrv8lP1_7c"
   },
   "outputs": [],
   "source": [
    "list_of_antonyms=[]\n",
    "from nltk.corpus import wordnet as wn\n",
    "for i in wn.all_synsets():\n",
    "    if i.pos() in ['a', 's']: \n",
    "        for j in i.lemmas(): \n",
    "            if j.antonyms(): \n",
    "                (j.name(), j.antonyms()[0].name()) and list_of_antonyms.append((j.name(), j.antonyms()[0].name()))\n",
    "dict_antonyms = dict((y, x) for x, y in list_of_antonyms)\n",
    "\n",
    "def find_antonyms(tokens_poss):\n",
    "    \"\"\" count how many antonyms in sentence \"\"\"\n",
    "    word_list = [word_pos[0] for word_pos in tokens_poss]\n",
    "    count = 0\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            if word in dict_antonyms:\n",
    "                if dict_antonyms[word] in word_list:\n",
    "                    count += 1\n",
    "        except Exception:\n",
    "            pass # don't found in dict\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlCmW8kg1nvk"
   },
   "outputs": [],
   "source": [
    "df['antonyms'] = token_pos.apply(find_antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322294,
     "status": "ok",
     "timestamp": 1581450498965,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "ZaTzzUyuH2_f",
    "outputId": "49daddd6-e620-40d2-a88f-034ab922e6f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: antonyms, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['antonyms'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WxIdaWbOfTWt"
   },
   "source": [
    "Longest word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnPGV-R84zz9"
   },
   "outputs": [],
   "source": [
    "def len_longest_word(tokens_poss):\n",
    "    \"\"\" check the length of the longest word \"\"\"\n",
    "    word_len_list = [(word_pos[0], len(word_pos[0]))  for word_pos in tokens_poss]\n",
    "    word_len_list = sorted(word_len_list, key=lambda x: x[1])\n",
    "\n",
    "    return word_len_list[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wav9yo3F5dnl"
   },
   "outputs": [],
   "source": [
    "df['longest_word'] = token_pos.apply(len_longest_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322276,
     "status": "ok",
     "timestamp": 1581450498969,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "vgIdL9AyH5Is",
    "outputId": "b867186c-b3ea-43dd-80c5-26e8631753cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7\n",
       "1     9\n",
       "2    12\n",
       "3     8\n",
       "4     8\n",
       "Name: longest_word, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['longest_word'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ugt-5xIh6Ss8"
   },
   "source": [
    "How many speical chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4KwaaTL6XIe"
   },
   "outputs": [],
   "source": [
    "def count_speical_chars(tokens_poss):\n",
    "    \"\"\" how many speical chars in string \"\"\"\n",
    "    bin_isalphanumberic_list = [not word_pos[0].isalnum() for word_pos in tokens_poss]\n",
    "\n",
    "    return np.sum(bin_isalphanumberic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HGJc7Zo7IO6"
   },
   "outputs": [],
   "source": [
    "df['speical_chars'] = token_pos.apply(count_speical_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322531,
     "status": "ok",
     "timestamp": 1581450499251,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "qtt-IHbdpmT8",
    "outputId": "f31d5d86-b399-47ab-9037-a2a6ce84fd85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    44\n",
       "2     5\n",
       "3     8\n",
       "4    14\n",
       "Name: speical_chars, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speical_chars'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ovx_UESSEqHK"
   },
   "source": [
    "more feaures from \"featuretools\" package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322520,
     "status": "ok",
     "timestamp": 1581450499253,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "yosZc5SSFTfh",
    "outputId": "5dbfc3c2-5879-4b8a-ae53-9a90c429aa18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: jokes_df\n",
       "  Entities:\n",
       "    jokes_df [Rows: 5000, Columns: 8]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = ft.EntitySet(\"jokes_df\")\n",
    "es.entity_from_dataframe(entity_id=\"jokes_df\",\n",
    "                          index=\"joke_id\",\n",
    "                          make_index=True,\n",
    "                          dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzDP2FnXGFi-"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DiversityScore()\n",
    "Calculates the overall complexity of the text based on the total\n",
    "\n",
    "LSA()\n",
    "Calculates the Latent Semantic Analysis Values of Text Input\n",
    "\n",
    "MeanCharactersPerWord()\n",
    "Determines the mean number of characters per word.\n",
    "\n",
    "PolarityScore()\n",
    "Calculates the polarity of a text on a scale from -1 (negative) to 1 (positive)\n",
    "\n",
    "PunctuationCount()\n",
    "Determines number of punctuation characters in a string.\n",
    "\n",
    "StopwordCount()\n",
    "Determines number of stopwords in a string.\n",
    "\n",
    "TitleWordCount()\n",
    "Determines the number of title words in a string.\n",
    "\n",
    "UpperCaseCount()\n",
    "Calculates the number of upper case letters in text.\n",
    "\"\"\"\n",
    "\n",
    "trans = [\n",
    "#     DiversityScore,\n",
    "#          LSA,\n",
    "         MeanCharactersPerWord,\n",
    "         UniversalSentenceEncoder,\n",
    "         PolarityScore, \n",
    "         PunctuationCount,\n",
    "         StopwordCount,\n",
    "         TitleWordCount,\n",
    "         UpperCaseCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E59B7fr2GA27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_customers, features_defs = ft.dfs(entityset=es,\n",
    "                  target_entity='jokes_df',\n",
    "                #   instance_ids=[\"joke\"],\n",
    "                  trans_primitives=trans,\n",
    "                  max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 355984,
     "status": "ok",
     "timestamp": 1581450532742,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "xlBts9qBPDFI",
    "outputId": "39ab3f84-da68-4ae8-d103-343b56d7539d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features to add:\n",
    "len(features_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pIG3LB6KHNV"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df['joke'],feature_matrix_customers], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 355966,
     "status": "ok",
     "timestamp": 1581450532745,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "4--aV_exLOkT",
    "outputId": "a813b70e-6b5c-4585-908e-c7a4377008c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke</th>\n",
       "      <th>score</th>\n",
       "      <th>ambiguous_words</th>\n",
       "      <th>best_score_similarity_words</th>\n",
       "      <th>antonyms</th>\n",
       "      <th>longest_word</th>\n",
       "      <th>speical_chars</th>\n",
       "      <th>MEAN_CHARACTERS_PER_WORD(joke)</th>\n",
       "      <th>UNIVERSAL_SENTENCE_ENCODER(joke)[0]</th>\n",
       "      <th>UNIVERSAL_SENTENCE_ENCODER(joke)[1]</th>\n",
       "      <th>...</th>\n",
       "      <th>UNIVERSAL_SENTENCE_ENCODER(joke)[507]</th>\n",
       "      <th>UNIVERSAL_SENTENCE_ENCODER(joke)[508]</th>\n",
       "      <th>UNIVERSAL_SENTENCE_ENCODER(joke)[509]</th>\n",
       "      <th>UNIVERSAL_SENTENCE_ENCODER(joke)[510]</th>\n",
       "      <th>UNIVERSAL_SENTENCE_ENCODER(joke)[511]</th>\n",
       "      <th>POLARITY_SCORE(joke)</th>\n",
       "      <th>PUNCTUATION_COUNT(joke)</th>\n",
       "      <th>STOPWORD_COUNT(joke)</th>\n",
       "      <th>TITLE_WORD_COUNT(joke)</th>\n",
       "      <th>UPPER_CASE_COUNT(joke)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate how you cant even say black paint anymo...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.919720</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.863636</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>-0.033341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057825</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>0.041815</td>\n",
       "      <td>-0.047018</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian raises his hand and says, “He’s in Heave...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.945242</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>4.584158</td>\n",
       "      <td>-0.041704</td>\n",
       "      <td>0.062440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068055</td>\n",
       "      <td>-0.035025</td>\n",
       "      <td>-0.039353</td>\n",
       "      <td>-0.045778</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.195</td>\n",
       "      <td>20.0</td>\n",
       "      <td>43</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I walked into a PETA adoption center and the r...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.932165</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>-0.033150</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072915</td>\n",
       "      <td>0.020479</td>\n",
       "      <td>0.054477</td>\n",
       "      <td>-0.046195</td>\n",
       "      <td>0.033442</td>\n",
       "      <td>0.079</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remember when you were a kid and when you crie...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.912641</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4.073171</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.058427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054912</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>-0.040058</td>\n",
       "      <td>-0.023789</td>\n",
       "      <td>-0.023233</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My boss said to me, \"you're the worst train dr...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914353</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>4.035714</td>\n",
       "      <td>-0.066581</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071312</td>\n",
       "      <td>-0.002545</td>\n",
       "      <td>-0.024180</td>\n",
       "      <td>-0.037230</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.345</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                joke  score  ambiguous_words  \\\n",
       "0  I hate how you cant even say black paint anymo...      1                4   \n",
       "1  Brian raises his hand and says, “He’s in Heave...      1                7   \n",
       "2  I walked into a PETA adoption center and the r...      1                3   \n",
       "3  Remember when you were a kid and when you crie...     15                2   \n",
       "4  My boss said to me, \"you're the worst train dr...      3                1   \n",
       "\n",
       "   best_score_similarity_words  antonyms  longest_word  speical_chars  \\\n",
       "0                     0.919720         0             7              4   \n",
       "1                     0.945242         0             9             44   \n",
       "2                     0.932165         0            12              5   \n",
       "3                     0.912641         0             8              8   \n",
       "4                     0.914353         0             8             14   \n",
       "\n",
       "   MEAN_CHARACTERS_PER_WORD(joke)  UNIVERSAL_SENTENCE_ENCODER(joke)[0]  \\\n",
       "0                        3.863636                             0.015197   \n",
       "1                        4.584158                            -0.041704   \n",
       "2                        4.750000                            -0.033150   \n",
       "3                        4.073171                             0.000824   \n",
       "4                        4.035714                            -0.066581   \n",
       "\n",
       "   UNIVERSAL_SENTENCE_ENCODER(joke)[1]  ...  \\\n",
       "0                            -0.033341  ...   \n",
       "1                             0.062440  ...   \n",
       "2                             0.027067  ...   \n",
       "3                             0.058427  ...   \n",
       "4                             0.072912  ...   \n",
       "\n",
       "   UNIVERSAL_SENTENCE_ENCODER(joke)[507]  \\\n",
       "0                              -0.057825   \n",
       "1                              -0.068055   \n",
       "2                              -0.072915   \n",
       "3                              -0.054912   \n",
       "4                              -0.071312   \n",
       "\n",
       "   UNIVERSAL_SENTENCE_ENCODER(joke)[508]  \\\n",
       "0                               0.019375   \n",
       "1                              -0.035025   \n",
       "2                               0.020479   \n",
       "3                               0.017778   \n",
       "4                              -0.002545   \n",
       "\n",
       "   UNIVERSAL_SENTENCE_ENCODER(joke)[509]  \\\n",
       "0                               0.041815   \n",
       "1                              -0.039353   \n",
       "2                               0.054477   \n",
       "3                              -0.040058   \n",
       "4                              -0.024180   \n",
       "\n",
       "   UNIVERSAL_SENTENCE_ENCODER(joke)[510]  \\\n",
       "0                              -0.047018   \n",
       "1                              -0.045778   \n",
       "2                              -0.046195   \n",
       "3                              -0.023789   \n",
       "4                              -0.037230   \n",
       "\n",
       "   UNIVERSAL_SENTENCE_ENCODER(joke)[511]  POLARITY_SCORE(joke)  \\\n",
       "0                              -0.016727                -0.083   \n",
       "1                              -0.006202                 0.195   \n",
       "2                               0.033442                 0.079   \n",
       "3                              -0.023233                -0.276   \n",
       "4                              -0.007027                -0.345   \n",
       "\n",
       "   PUNCTUATION_COUNT(joke)  STOPWORD_COUNT(joke)  TITLE_WORD_COUNT(joke)  \\\n",
       "0                      4.0                     7                     4.0   \n",
       "1                     20.0                    43                    25.0   \n",
       "2                      5.0                    11                     5.0   \n",
       "3                      8.0                    20                     3.0   \n",
       "4                     14.0                    10                     4.0   \n",
       "\n",
       "   UPPER_CASE_COUNT(joke)  \n",
       "0                     4.0  \n",
       "1                    25.0  \n",
       "2                     8.0  \n",
       "3                     3.0  \n",
       "4                     4.0  \n",
       "\n",
       "[5 rows x 525 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uc_DCwlfmzr9"
   },
   "source": [
    "Add object counter features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSVA21zpqH0J"
   },
   "outputs": [],
   "source": [
    "df['joke_tokenized'] = df['joke'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYEVhbrB5k_8"
   },
   "outputs": [],
   "source": [
    "def add_object_count_cols(df,tokenized_col):\n",
    "  df['temp'] = df[tokenized_col].apply(lambda x: [ent.label_ for ent in x.ents])\n",
    "  mlb = MultiLabelBinarizer()\n",
    "  mlb.fit(df['temp'])\n",
    "  df = df.join(pd.DataFrame(mlb.transform(df['temp']),\n",
    "                            columns=mlb.classes_,\n",
    "                            index=df.index))\n",
    "  del df['temp']\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAxgjG-snC6D"
   },
   "outputs": [],
   "source": [
    "df = add_object_count_cols(df,'joke_tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435932,
     "status": "ok",
     "timestamp": 1581450612742,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "HlEfEbzpqEu4",
    "outputId": "4686465f-95cb-4c98-9327-0d84b2d3e153"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 544)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfvrRp9avJkH"
   },
   "source": [
    "Add Part-of-Speech features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jtad5rl16fcb"
   },
   "outputs": [],
   "source": [
    "def add_pos_count_cols(df,tokenized_col):\n",
    "  df['temp'] = df[tokenized_col].apply(lambda x: [ent.pos_ for ent in x])\n",
    "  mlb = MultiLabelBinarizer()\n",
    "  mlb.fit(df['temp'])\n",
    "  df = df.join(pd.DataFrame(mlb.transform(df['temp']),\n",
    "                            columns=mlb.classes_,\n",
    "                            index=df.index))\n",
    "  del df['temp']\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgwW07-r89vK"
   },
   "outputs": [],
   "source": [
    "df = add_pos_count_cols(df,'joke_tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435915,
     "status": "ok",
     "timestamp": 1581450612748,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "TVF_1YE4qvnU",
    "outputId": "efedb27e-2435-4132-da43-706a4e44f5be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 562)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIyH0nVfypLe"
   },
   "source": [
    "Text cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tboVSq1Uyrv5"
   },
   "outputs": [],
   "source": [
    "def replace_non_eng_punct(txt):\n",
    "    return re.sub(r'/[^a-zA-Z0-9\\s,.?!]/','*',txt).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBMUKy1xy_3Q"
   },
   "outputs": [],
   "source": [
    "def replace_escape(txt):\n",
    "    updated_txt = re.sub(r'\\n|\\t|&amp;',' ',txt)\n",
    "    return updated_txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsboyvCry5-3"
   },
   "outputs": [],
   "source": [
    "def remove_multi_spaces(txt):\n",
    "    return re.sub(' +', ' ',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hWfly7ny9d_"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(document):\n",
    "  #         # Remove all the special characters\n",
    "  document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "  #         # remove all single characters\n",
    "  document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "  #         # Remove single characters from the start\n",
    "  document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "  # Substituting multiple spaces with single space\n",
    "  document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "  # Removing prefixed 'b'\n",
    "  document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "  # Converting to Lowercase\n",
    "  document = document.lower()\n",
    "\n",
    "  return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bh13H2ps1OHG"
   },
   "outputs": [],
   "source": [
    "df['joke_text_processed'] = df['joke'].apply(replace_non_eng_punct).apply(remove_multi_spaces).apply(replace_escape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxMKxrmq1UVh"
   },
   "outputs": [],
   "source": [
    "df['joke_text_processed'] = df['joke_text_processed'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaAIrp-G2hFS"
   },
   "outputs": [],
   "source": [
    "df['joke_processed_tokenized'] = df['joke_text_processed'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 509570,
     "status": "ok",
     "timestamp": 1581450686457,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "Kl9BUsut1ZHe",
    "outputId": "bbb61e94-930f-4427-f390-9e9b8363f3f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "did you hear about leatherface jewish cousin he was also serial killer he liked to dig up the corpses of women and use their skin to furnish his house after the police arrested him they discovered whole morbid collection of objects he had belt made out of ears lampshade made from stitched together faces they even found labia menora "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['joke_processed_tokenized'][55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4iDtKziaxsS2"
   },
   "source": [
    "Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuhWUhT8chpJ"
   },
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatize_remove_stop_words = lambda x: nlp(' '.join([stemmer.lemmatize(str(word)) for word in x if str(word) not in stop_words]))\n",
    "lemmatize_remove_stop_words_str = lambda x: ' '.join([stemmer.lemmatize(str(word)) for word in x if str(word) not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDFb6eUycg9K"
   },
   "outputs": [],
   "source": [
    "df['joke_processed_tokenized_stemmed'] = df['joke_processed_tokenized'].apply(lemmatize_remove_stop_words)\n",
    "df['joke_processed_tokenized_stemmed_str'] = df['joke_processed_tokenized'].apply(lemmatize_remove_stop_words_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_olygE_5vqbV"
   },
   "source": [
    "Build embedding features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uB-s1hxzGWiZ"
   },
   "outputs": [],
   "source": [
    "# def get_sentence_embeddings(sentence):\n",
    "#   embedding = np.zeros((len(sentence),300))\n",
    "#   for ind,token in enumerate(sentence):\n",
    "#     if str(token) in model_embeddings.vocab.keys():\n",
    "#       embedding[ind] = model_embeddings[str(token)]\n",
    "#     else:\n",
    "#       pass\n",
    "#   embedding = embedding.mean(axis = 0)\n",
    "#   return embedding\n",
    "\n",
    "# def add_pos_count_cols(df,tokenized_col):\n",
    "#   df['temp'] = df[tokenized_col].apply(lambda x: [ent.pos_ for ent in x])\n",
    "#   mlb = MultiLabelBinarizer()\n",
    "#   mlb.fit(df['temp'])\n",
    "#   df = df.join(pd.DataFrame(mlb.transform(df['temp']),\n",
    "#                             columns=mlb.classes_,\n",
    "#                             index=df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gIYJNDewSKq"
   },
   "outputs": [],
   "source": [
    "# df['joke_embbedings'] = df['joke_processed_tokenized_stemmed'].apply(get_sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zP7X8Lr64Kqs"
   },
   "outputs": [],
   "source": [
    "# classes = [f'sentence_vec_{i}' for i in range(300)]\n",
    "# df = df.merge(pd.DataFrame(df['joke_embbedings'].tolist(), columns = classes, index= df['joke_embbedings'].index),\n",
    "#                            how='left',left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1581454000097,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "-tP_ER8wPnq7",
    "outputId": "320ecfd8-cada-4f19-96fb-ef768f81c794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 566)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cy1RYClJvxWi"
   },
   "source": [
    "Build total words / total chars features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZSaVpWFKxJh"
   },
   "outputs": [],
   "source": [
    "df['total_words'] = df['joke_tokenized'].apply(len)\n",
    "df['total_chars'] = df['joke'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4moOzxZRMKu"
   },
   "source": [
    "Split to train/test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lR6vMIRMQBHT"
   },
   "outputs": [],
   "source": [
    "target = 'score'\n",
    "X = df[df.columns[df.columns!=target]]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FacmBwsqRDsy"
   },
   "outputs": [],
   "source": [
    "## Use validation set\n",
    "# Split earlier to avoid leakage\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True)\n",
    "X_test.reset_index(inplace = True)\n",
    "y_train = y_train.reset_index()['score']\n",
    "y_test = y_test.reset_index()['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 568)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:,X_train.columns != 'index']\n",
    "X_test = X_test.loc[:,X_test.columns != 'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbOLxbEGRHgj"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input='content', decode_error='strict', lowercase=True, stop_words='english', ngram_range=(1, 2), \n",
    "                max_features=1000, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYY6JNGzRK_7"
   },
   "source": [
    "Add TfidfVectorizer features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6T7JCbRWRR18"
   },
   "outputs": [],
   "source": [
    "vectorizer.fit(X_train['joke_processed_tokenized_stemmed_str'])\n",
    "tfidf_vec_train = vectorizer.transform(X_train['joke_processed_tokenized_stemmed_str']).toarray()\n",
    "tfidf_vec_test = vectorizer.transform(X_test['joke_processed_tokenized_stemmed_str']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9j7M6KPRdbk"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.merge(pd.DataFrame(tfidf_vec_train,columns=vectorizer.vocabulary_),how='left',left_index=True,right_index=True)\n",
    "X_test = X_test.merge(pd.DataFrame(tfidf_vec_test,columns=vectorizer.vocabulary_),how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Missing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_data(df):\n",
    "  \"\"\" \n",
    "      params: dataframe\n",
    "      return: data of missing values, if have some.\n",
    "  \"\"\"\n",
    "  flag=df.isna().sum().any()\n",
    "  if flag==True:\n",
    "      total = df.isnull().sum()\n",
    "      percent = (df.isnull().sum())*100/(df.isnull().count())\n",
    "      output = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "      data_type = []\n",
    "      for col in df.columns:\n",
    "          dtype = str(df[col].dtype)\n",
    "          data_type.append(dtype)\n",
    "      output['Types'] = data_type\n",
    "      return(output[output['Percent'] > 0].sort_values(by='Percent', ascending=False))\n",
    "  else:\n",
    "      return(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fP-cByjdSbN7"
   },
   "source": [
    "Dump output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651,
     "status": "error",
     "timestamp": 1581454013210,
     "user": {
      "displayName": "אבי ברזני",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6SboJ8QzC3mjovhxzlMpM2Q47AIYXxejuQIAx8H8=s64",
      "userId": "02844919183182579738"
     },
     "user_tz": -120
    },
    "id": "QXaBIIxlSiF7",
    "outputId": "706a9b6d-61e7-4406-e06d-9fa18b77a339"
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(X_train, path + \"X_train.pkl\")\n",
    "pd.to_pickle(X_test, path + \"X_test.pkl\")\n",
    "pd.to_pickle(y_train, path + \"y_train.pkl\")\n",
    "pd.to_pickle(y_test, path + \"y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FeatureEngineering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
