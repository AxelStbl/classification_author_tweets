{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T12:57:59.333516Z",
     "start_time": "2020-02-05T12:57:59.318309Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models.fasttext import FastText\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import WordPunctTokenizer\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction import text\n",
    "import nltk\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:09:12.564283Z",
     "start_time": "2020-02-05T13:09:12.435767Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:10:08.046816Z",
     "start_time": "2020-02-05T13:10:08.040409Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:05:52.962579Z",
     "start_time": "2020-02-05T13:05:52.956572Z"
    }
   },
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:30:38.808656Z",
     "start_time": "2020-02-05T13:30:38.799381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at                    object\n",
       "display_text_range            object\n",
       "entities                      object\n",
       "extended_entities             object\n",
       "favorite_count                 int64\n",
       "favorited                       bool\n",
       "full_text                     object\n",
       "id                             int64\n",
       "id_str                         int64\n",
       "in_reply_to_screen_name       object\n",
       "in_reply_to_status_id        float64\n",
       "in_reply_to_status_id_str    float64\n",
       "in_reply_to_user_id          float64\n",
       "in_reply_to_user_id_str      float64\n",
       "is_quote_status                 bool\n",
       "lang                          object\n",
       "place                         object\n",
       "possibly_sensitive            object\n",
       "quoted_status                 object\n",
       "quoted_status_id             float64\n",
       "quoted_status_id_str         float64\n",
       "quoted_status_permalink       object\n",
       "retweet_count                  int64\n",
       "retweeted                       bool\n",
       "retweeted_status              object\n",
       "source                        object\n",
       "truncated                       bool\n",
       "user                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:45:43.405136Z",
     "start_time": "2020-02-05T13:45:43.397615Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_na_values():\n",
    "    all_cols = df.columns\n",
    "    print(\"Total shape: \", df.shape)\n",
    "    for col in all_cols:\n",
    "        if(len(df[df[col].isna()][col]) != 0):\n",
    "            print(f\"Na values for col {col}: {len(df[df[col].isna()][col])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:48:31.391163Z",
     "start_time": "2020-02-05T13:48:31.380070Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_null_values():\n",
    "    all_cols = df.columns\n",
    "    print(\"Total shape: \", df.shape)\n",
    "    for col in all_cols:\n",
    "        if(len(df[df[col].isnull()][col]) != 0):\n",
    "            print(f\"Null values for col {col}: {len(df[df[col].isna()][col])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:45:35.739860Z",
     "start_time": "2020-02-05T13:45:35.621686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shape:  (6159, 28)\n",
      "Na values for col extended_entities: 5370\n",
      "Na values for col in_reply_to_screen_name: 2514\n",
      "Na values for col in_reply_to_status_id: 2540\n",
      "Na values for col in_reply_to_status_id_str: 2540\n",
      "Na values for col in_reply_to_user_id: 2514\n",
      "Na values for col in_reply_to_user_id_str: 2514\n",
      "Na values for col place: 6156\n",
      "Na values for col possibly_sensitive: 5161\n",
      "Na values for col quoted_status: 6041\n",
      "Na values for col quoted_status_id: 6002\n",
      "Na values for col quoted_status_id_str: 6002\n",
      "Na values for col quoted_status_permalink: 6002\n",
      "Na values for col retweeted_status: 5492\n"
     ]
    }
   ],
   "source": [
    "print_na_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:48:34.531559Z",
     "start_time": "2020-02-05T13:48:34.429916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shape:  (6159, 28)\n",
      "Null values for col extended_entities: 5370\n",
      "Null values for col in_reply_to_screen_name: 2514\n",
      "Null values for col in_reply_to_status_id: 2540\n",
      "Null values for col in_reply_to_status_id_str: 2540\n",
      "Null values for col in_reply_to_user_id: 2514\n",
      "Null values for col in_reply_to_user_id_str: 2514\n",
      "Null values for col place: 6156\n",
      "Null values for col possibly_sensitive: 5161\n",
      "Null values for col quoted_status: 6041\n",
      "Null values for col quoted_status_id: 6002\n",
      "Null values for col quoted_status_id_str: 6002\n",
      "Null values for col quoted_status_permalink: 6002\n",
      "Null values for col retweeted_status: 5492\n"
     ]
    }
   ],
   "source": [
    "print_null_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:31:21.734249Z",
     "start_time": "2020-02-05T13:31:21.666126Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6159.000000</td>\n",
       "      <td>6.159000e+03</td>\n",
       "      <td>6.159000e+03</td>\n",
       "      <td>3.619000e+03</td>\n",
       "      <td>3.619000e+03</td>\n",
       "      <td>3.645000e+03</td>\n",
       "      <td>3.645000e+03</td>\n",
       "      <td>1.570000e+02</td>\n",
       "      <td>1.570000e+02</td>\n",
       "      <td>6159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2061.684202</td>\n",
       "      <td>1.010494e+18</td>\n",
       "      <td>1.010494e+18</td>\n",
       "      <td>1.073790e+18</td>\n",
       "      <td>1.073790e+18</td>\n",
       "      <td>2.625706e+17</td>\n",
       "      <td>2.625706e+17</td>\n",
       "      <td>9.742269e+17</td>\n",
       "      <td>9.742269e+17</td>\n",
       "      <td>992.399578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14008.929534</td>\n",
       "      <td>1.692469e+17</td>\n",
       "      <td>1.692469e+17</td>\n",
       "      <td>1.023473e+17</td>\n",
       "      <td>1.023473e+17</td>\n",
       "      <td>4.185165e+17</td>\n",
       "      <td>4.185165e+17</td>\n",
       "      <td>1.526749e+17</td>\n",
       "      <td>1.526749e+17</td>\n",
       "      <td>5918.925656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.568955e+17</td>\n",
       "      <td>5.568955e+17</td>\n",
       "      <td>3.768168e+09</td>\n",
       "      <td>3.768168e+09</td>\n",
       "      <td>1.332121e+06</td>\n",
       "      <td>1.332121e+06</td>\n",
       "      <td>6.105016e+17</td>\n",
       "      <td>6.105016e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.894714e+17</td>\n",
       "      <td>9.894714e+17</td>\n",
       "      <td>1.014719e+18</td>\n",
       "      <td>1.014719e+18</td>\n",
       "      <td>3.336645e+08</td>\n",
       "      <td>3.336645e+08</td>\n",
       "      <td>8.877338e+17</td>\n",
       "      <td>8.877338e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.040752e+18</td>\n",
       "      <td>1.040752e+18</td>\n",
       "      <td>1.080976e+18</td>\n",
       "      <td>1.080976e+18</td>\n",
       "      <td>1.413627e+09</td>\n",
       "      <td>1.413627e+09</td>\n",
       "      <td>9.903306e+17</td>\n",
       "      <td>9.903306e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.125954e+18</td>\n",
       "      <td>1.125954e+18</td>\n",
       "      <td>1.145731e+18</td>\n",
       "      <td>1.145731e+18</td>\n",
       "      <td>7.326784e+17</td>\n",
       "      <td>7.326784e+17</td>\n",
       "      <td>1.058449e+18</td>\n",
       "      <td>1.058449e+18</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>462885.000000</td>\n",
       "      <td>1.222370e+18</td>\n",
       "      <td>1.222370e+18</td>\n",
       "      <td>1.222370e+18</td>\n",
       "      <td>1.222370e+18</td>\n",
       "      <td>1.219086e+18</td>\n",
       "      <td>1.219086e+18</td>\n",
       "      <td>1.216535e+18</td>\n",
       "      <td>1.216535e+18</td>\n",
       "      <td>145351.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count            id        id_str  in_reply_to_status_id  \\\n",
       "count     6159.000000  6.159000e+03  6.159000e+03           3.619000e+03   \n",
       "mean      2061.684202  1.010494e+18  1.010494e+18           1.073790e+18   \n",
       "std      14008.929534  1.692469e+17  1.692469e+17           1.023473e+17   \n",
       "min          0.000000  5.568955e+17  5.568955e+17           3.768168e+09   \n",
       "25%          1.000000  9.894714e+17  9.894714e+17           1.014719e+18   \n",
       "50%          7.000000  1.040752e+18  1.040752e+18           1.080976e+18   \n",
       "75%         83.000000  1.125954e+18  1.125954e+18           1.145731e+18   \n",
       "max     462885.000000  1.222370e+18  1.222370e+18           1.222370e+18   \n",
       "\n",
       "       in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "count               3.619000e+03         3.645000e+03   \n",
       "mean                1.073790e+18         2.625706e+17   \n",
       "std                 1.023473e+17         4.185165e+17   \n",
       "min                 3.768168e+09         1.332121e+06   \n",
       "25%                 1.014719e+18         3.336645e+08   \n",
       "50%                 1.080976e+18         1.413627e+09   \n",
       "75%                 1.145731e+18         7.326784e+17   \n",
       "max                 1.222370e+18         1.219086e+18   \n",
       "\n",
       "       in_reply_to_user_id_str  quoted_status_id  quoted_status_id_str  \\\n",
       "count             3.645000e+03      1.570000e+02          1.570000e+02   \n",
       "mean              2.625706e+17      9.742269e+17          9.742269e+17   \n",
       "std               4.185165e+17      1.526749e+17          1.526749e+17   \n",
       "min               1.332121e+06      6.105016e+17          6.105016e+17   \n",
       "25%               3.336645e+08      8.877338e+17          8.877338e+17   \n",
       "50%               1.413627e+09      9.903306e+17          9.903306e+17   \n",
       "75%               7.326784e+17      1.058449e+18          1.058449e+18   \n",
       "max               1.219086e+18      1.216535e+18          1.216535e+18   \n",
       "\n",
       "       retweet_count  \n",
       "count    6159.000000  \n",
       "mean      992.399578  \n",
       "std      5918.925656  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%        15.000000  \n",
       "max    145351.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:55:52.762834Z",
     "start_time": "2020-02-05T13:55:52.725092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>lang</th>\n",
       "      <th>place</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Jan 29 01:47:13 +0000 2020</td>\n",
       "      <td>[11, 79]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>@Spothebro yes actually but it wasn’t sexy. mo...</td>\n",
       "      <td>1222335355543785472</td>\n",
       "      <td>1222335355543785472</td>\n",
       "      <td>Spothebro</td>\n",
       "      <td>1.222335e+18</td>\n",
       "      <td>1.222335e+18</td>\n",
       "      <td>1.788721e+08</td>\n",
       "      <td>1.788721e+08</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Jan 28 18:38:44 +0000 2020</td>\n",
       "      <td>[10, 53]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>451</td>\n",
       "      <td>False</td>\n",
       "      <td>@blaizun1 12 year old danya was absolutely dev...</td>\n",
       "      <td>1222227523150344193</td>\n",
       "      <td>1222227523150344193</td>\n",
       "      <td>blaizun1</td>\n",
       "      <td>1.222227e+18</td>\n",
       "      <td>1.222227e+18</td>\n",
       "      <td>1.164471e+18</td>\n",
       "      <td>1.164471e+18</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Jan 28 18:20:25 +0000 2020</td>\n",
       "      <td>[13, 35]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 1222222908581265408, 'id_str...</td>\n",
       "      <td>454</td>\n",
       "      <td>False</td>\n",
       "      <td>@thats_messy i stole it from myself https://t....</td>\n",
       "      <td>1222222914583498752</td>\n",
       "      <td>1222222914583498752</td>\n",
       "      <td>thats_messy</td>\n",
       "      <td>1.222223e+18</td>\n",
       "      <td>1.222223e+18</td>\n",
       "      <td>1.102349e+18</td>\n",
       "      <td>1.102349e+18</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Jan 28 18:14:47 +0000 2020</td>\n",
       "      <td>[0, 246]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34480</td>\n",
       "      <td>False</td>\n",
       "      <td>one time in middle school this kid was like \"u...</td>\n",
       "      <td>1222221497390944256</td>\n",
       "      <td>1222221497390944256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1066</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Jan 28 02:39:15 +0000 2020</td>\n",
       "      <td>[13, 33]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>@KevinWicks2 peter isn’t cute man</td>\n",
       "      <td>1221986062026887168</td>\n",
       "      <td>1221986062026887168</td>\n",
       "      <td>KevinWicks2</td>\n",
       "      <td>1.221986e+18</td>\n",
       "      <td>1.221986e+18</td>\n",
       "      <td>1.538617e+09</td>\n",
       "      <td>1.538617e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at display_text_range  \\\n",
       "0  Wed Jan 29 01:47:13 +0000 2020           [11, 79]   \n",
       "1  Tue Jan 28 18:38:44 +0000 2020           [10, 53]   \n",
       "2  Tue Jan 28 18:20:25 +0000 2020           [13, 35]   \n",
       "3  Tue Jan 28 18:14:47 +0000 2020           [0, 246]   \n",
       "4  Tue Jan 28 02:39:15 +0000 2020           [13, 33]   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "2  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "3  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "4  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0                                                NaN               4   \n",
       "1                                                NaN             451   \n",
       "2  {'media': [{'id': 1222222908581265408, 'id_str...             454   \n",
       "3                                                NaN           34480   \n",
       "4                                                NaN               1   \n",
       "\n",
       "   favorited                                          full_text  \\\n",
       "0      False  @Spothebro yes actually but it wasn’t sexy. mo...   \n",
       "1      False  @blaizun1 12 year old danya was absolutely dev...   \n",
       "2      False  @thats_messy i stole it from myself https://t....   \n",
       "3      False  one time in middle school this kid was like \"u...   \n",
       "4      False                  @KevinWicks2 peter isn’t cute man   \n",
       "\n",
       "                    id               id_str in_reply_to_screen_name  \\\n",
       "0  1222335355543785472  1222335355543785472               Spothebro   \n",
       "1  1222227523150344193  1222227523150344193                blaizun1   \n",
       "2  1222222914583498752  1222222914583498752             thats_messy   \n",
       "3  1222221497390944256  1222221497390944256                     NaN   \n",
       "4  1221986062026887168  1221986062026887168             KevinWicks2   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0           1.222335e+18               1.222335e+18         1.788721e+08   \n",
       "1           1.222227e+18               1.222227e+18         1.164471e+18   \n",
       "2           1.222223e+18               1.222223e+18         1.102349e+18   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4           1.221986e+18               1.221986e+18         1.538617e+09   \n",
       "\n",
       "   in_reply_to_user_id_str  is_quote_status lang place possibly_sensitive  \\\n",
       "0             1.788721e+08            False   en   NaN                NaN   \n",
       "1             1.164471e+18            False   en   NaN                NaN   \n",
       "2             1.102349e+18            False   en   NaN              False   \n",
       "3                      NaN            False   en   NaN                NaN   \n",
       "4             1.538617e+09            False   en   NaN                NaN   \n",
       "\n",
       "  quoted_status  quoted_status_id  quoted_status_id_str  \\\n",
       "0           NaN               NaN                   NaN   \n",
       "1           NaN               NaN                   NaN   \n",
       "2           NaN               NaN                   NaN   \n",
       "3           NaN               NaN                   NaN   \n",
       "4           NaN               NaN                   NaN   \n",
       "\n",
       "  quoted_status_permalink  retweet_count  retweeted retweeted_status  \\\n",
       "0                     NaN              0      False              NaN   \n",
       "1                     NaN              2      False              NaN   \n",
       "2                     NaN              0      False              NaN   \n",
       "3                     NaN           1066      False              NaN   \n",
       "4                     NaN              0      False              NaN   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "\n",
       "                                                user  \n",
       "0  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "1  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "2  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "3  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "4  {'id': 2492132730, 'id_str': '2492132730', 'na...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:26:01.687115Z",
     "start_time": "2020-02-05T13:26:01.680742Z"
    }
   },
   "outputs": [],
   "source": [
    "# first preselection based on description:\n",
    "not_to_use = [\"contributors\", \"coordinates\", \"geo\", \"id\",\"id_str\",\"in_reply_to_status_id\",\"in_reply_to_status_id_str\",\"in_reply_to_user_id\",\"in_reply_to_user_id_str\",\"quoted_status_id\",\"quoted_status_id_str\"]\n",
    "df = df.drop(columns=to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have as many ID as rows we can drop id column since we won't use it to scrape other tweets or see responses\n",
    "df= df.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'joke' column and remove unnecessary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:11:22.853759Z",
     "start_time": "2020-02-05T13:11:22.813345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>full_text</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>lang</th>\n",
       "      <th>place</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Jan 29 01:47:13 +0000 2020</td>\n",
       "      <td>[11, 79]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>@Spothebro yes actually but it wasn’t sexy. mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1222335355543785472</td>\n",
       "      <td>1222335355543785472</td>\n",
       "      <td>Spothebro</td>\n",
       "      <td>1.222335e+18</td>\n",
       "      <td>1.222335e+18</td>\n",
       "      <td>1.788721e+08</td>\n",
       "      <td>1.788721e+08</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 28 18:38:44 +0000 2020</td>\n",
       "      <td>[10, 53]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>451</td>\n",
       "      <td>False</td>\n",
       "      <td>@blaizun1 12 year old danya was absolutely dev...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1222227523150344193</td>\n",
       "      <td>1222227523150344193</td>\n",
       "      <td>blaizun1</td>\n",
       "      <td>1.222227e+18</td>\n",
       "      <td>1.222227e+18</td>\n",
       "      <td>1.164471e+18</td>\n",
       "      <td>1.164471e+18</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 28 18:20:25 +0000 2020</td>\n",
       "      <td>[13, 35]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 1222222908581265408, 'id_str...</td>\n",
       "      <td>454</td>\n",
       "      <td>False</td>\n",
       "      <td>@thats_messy i stole it from myself https://t....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1222222914583498752</td>\n",
       "      <td>1222222914583498752</td>\n",
       "      <td>thats_messy</td>\n",
       "      <td>1.222223e+18</td>\n",
       "      <td>1.222223e+18</td>\n",
       "      <td>1.102349e+18</td>\n",
       "      <td>1.102349e+18</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 28 18:14:47 +0000 2020</td>\n",
       "      <td>[0, 246]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34480</td>\n",
       "      <td>False</td>\n",
       "      <td>one time in middle school this kid was like \"u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1222221497390944256</td>\n",
       "      <td>1222221497390944256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1066</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 28 02:39:15 +0000 2020</td>\n",
       "      <td>[13, 33]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>@KevinWicks2 peter isn’t cute man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1221986062026887168</td>\n",
       "      <td>1221986062026887168</td>\n",
       "      <td>KevinWicks2</td>\n",
       "      <td>1.221986e+18</td>\n",
       "      <td>1.221986e+18</td>\n",
       "      <td>1.538617e+09</td>\n",
       "      <td>1.538617e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2492132730, 'id_str': '2492132730', 'na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Wed Jan 29 01:47:13 +0000 2020   \n",
       "1           NaN          NaN  Tue Jan 28 18:38:44 +0000 2020   \n",
       "2           NaN          NaN  Tue Jan 28 18:20:25 +0000 2020   \n",
       "3           NaN          NaN  Tue Jan 28 18:14:47 +0000 2020   \n",
       "4           NaN          NaN  Tue Jan 28 02:39:15 +0000 2020   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0           [11, 79]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1           [10, 53]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "2           [13, 35]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "3           [0, 246]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "4           [13, 33]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0                                                NaN               4   \n",
       "1                                                NaN             451   \n",
       "2  {'media': [{'id': 1222222908581265408, 'id_str...             454   \n",
       "3                                                NaN           34480   \n",
       "4                                                NaN               1   \n",
       "\n",
       "   favorited                                          full_text  geo  \\\n",
       "0      False  @Spothebro yes actually but it wasn’t sexy. mo...  NaN   \n",
       "1      False  @blaizun1 12 year old danya was absolutely dev...  NaN   \n",
       "2      False  @thats_messy i stole it from myself https://t....  NaN   \n",
       "3      False  one time in middle school this kid was like \"u...  NaN   \n",
       "4      False                  @KevinWicks2 peter isn’t cute man  NaN   \n",
       "\n",
       "                    id               id_str in_reply_to_screen_name  \\\n",
       "0  1222335355543785472  1222335355543785472               Spothebro   \n",
       "1  1222227523150344193  1222227523150344193                blaizun1   \n",
       "2  1222222914583498752  1222222914583498752             thats_messy   \n",
       "3  1222221497390944256  1222221497390944256                     NaN   \n",
       "4  1221986062026887168  1221986062026887168             KevinWicks2   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0           1.222335e+18               1.222335e+18         1.788721e+08   \n",
       "1           1.222227e+18               1.222227e+18         1.164471e+18   \n",
       "2           1.222223e+18               1.222223e+18         1.102349e+18   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4           1.221986e+18               1.221986e+18         1.538617e+09   \n",
       "\n",
       "   in_reply_to_user_id_str  is_quote_status lang place possibly_sensitive  \\\n",
       "0             1.788721e+08            False   en   NaN                NaN   \n",
       "1             1.164471e+18            False   en   NaN                NaN   \n",
       "2             1.102349e+18            False   en   NaN              False   \n",
       "3                      NaN            False   en   NaN                NaN   \n",
       "4             1.538617e+09            False   en   NaN                NaN   \n",
       "\n",
       "  quoted_status  quoted_status_id  quoted_status_id_str  \\\n",
       "0           NaN               NaN                   NaN   \n",
       "1           NaN               NaN                   NaN   \n",
       "2           NaN               NaN                   NaN   \n",
       "3           NaN               NaN                   NaN   \n",
       "4           NaN               NaN                   NaN   \n",
       "\n",
       "  quoted_status_permalink  retweet_count  retweeted retweeted_status  \\\n",
       "0                     NaN              0      False              NaN   \n",
       "1                     NaN              2      False              NaN   \n",
       "2                     NaN              0      False              NaN   \n",
       "3                     NaN           1066      False              NaN   \n",
       "4                     NaN              0      False              NaN   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      False   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "\n",
       "                                                user  \n",
       "0  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "1  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "2  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "3  {'id': 2492132730, 'id_str': '2492132730', 'na...  \n",
       "4  {'id': 2492132730, 'id_str': '2492132730', 'na...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joke'] = df['title'] +'. '+ df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,['joke','score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process text:\n",
    "- Remove punctuation\n",
    "- Replace escape characters\n",
    "- Remove extra spaces\n",
    "- Remove single characters\n",
    "- Remove prefixed 'b'\n",
    "- Lowercase all characters\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_non_eng_punct(txt):\n",
    "    return re.sub(r'/[^a-zA-Z0-9\\s,.?!]/','*',txt).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_url(txt):\n",
    "#     return re.sub(r'https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}','',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_escape(txt):\n",
    "    updated_txt = re.sub(r'\\n|\\t|&amp;',' ',txt)\n",
    "    return updated_txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multi_spaces(txt):\n",
    "    return re.sub(' +', ' ',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(document):\n",
    "#         # Remove all the special characters\n",
    "        document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "#         # remove all single characters\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "#         # Remove single characters from the start\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "        # Lemmatization\n",
    "        tokens = document.split()\n",
    "        tokens = [stemmer.lemmatize(word) for word in tokens]\n",
    "        tokens = [word for word in tokens if word not in en_stop]\n",
    "        tokens = [word for word in tokens if len(word) > 3]\n",
    "\n",
    "        preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "        return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joke'] = df['joke'].apply(replace_non_eng_punct).apply(remove_multi_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joke_preprocessed'] = df['joke'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample before/after preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate how you cant even say black paint anymore. Now I have to say \"Leroy can you please paint the fence?\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['joke'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hate cant even black paint anymore leroy please paint fence'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['joke_preprocessed'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create joke tokens list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_punct(txt):\n",
    "    return re.split(r'(\\W)',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joke_tokens'] = df['joke_preprocessed'].apply(split_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(lst):\n",
    "    return [x for x in lst if (x != ' ') and (x != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joke_tokens'] = df['joke_tokens'].apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'score'\n",
    "tokens_col = 'joke_preprocessed'\n",
    "X = df[tokens_col].to_numpy()\n",
    "y = df[target_col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \\\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(y_train.reshape(-1,1))\n",
    "y_train = scaler.transform(y_train.reshape(-1,1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1,1)).reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for s in df['joke_tokens']:\n",
    "    for w in s:\n",
    "        cnt[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2 = cnt.most_common(1000)\n",
    "vocab2 = [i[0] for i in vocab2]\n",
    "# vocab_id = defaultdict(int)\n",
    "# for ind,w in enumerate(vocab):\n",
    "#     vocab_id[w[0]] = ind+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate TFIDF/CountVectorizer features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_filter_vec2 = np.vectorize(lambda x: ' '.join([i for i in x.split(' ') if i in vocab2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = concat_filter_vec2(X_train)\n",
    "X_test = concat_filter_vec2(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scientist came inside fuck dude hell away'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tf = TfidfVectorizer()\n",
    "X_train_tf = vectorizer_tf.fit_transform(X_train).toarray()\n",
    "X_test_tf = vectorizer_tf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CountVectorizer()\n",
    "X_train_count = c.fit_transform(X_train).toarray()\n",
    "X_test_count = c.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33728993, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106393, 1000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Embedding, TimeDistributed, recurrent\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=1000, activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(1, activation='relu',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               128128    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 161,281\n",
      "Trainable params: 161,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 85114 samples, validate on 21279 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yaniv\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "85114/85114 [==============================] - 5s 54us/step - loss: 4.4947 - mean_squared_error: 5.1584e-04 - val_loss: 4.0598 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 2/20\n",
      "85114/85114 [==============================] - 4s 42us/step - loss: 3.7326 - mean_squared_error: 5.1399e-04 - val_loss: 3.4221 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 3/20\n",
      "85114/85114 [==============================] - 3s 38us/step - loss: 3.1471 - mean_squared_error: 5.1399e-04 - val_loss: 2.8858 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 4/20\n",
      "85114/85114 [==============================] - 3s 40us/step - loss: 2.6539 - mean_squared_error: 5.1399e-04 - val_loss: 2.4336 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 5/20\n",
      "85114/85114 [==============================] - 4s 43us/step - loss: 2.2381 - mean_squared_error: 5.1399e-04 - val_loss: 2.0524 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 6/20\n",
      "85114/85114 [==============================] - 3s 38us/step - loss: 1.8875 - mean_squared_error: 5.1399e-04 - val_loss: 1.7309 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 7/20\n",
      "85114/85114 [==============================] - 3s 41us/step - loss: 1.5918 - mean_squared_error: 5.1399e-04 - val_loss: 1.4598 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 8/20\n",
      "85114/85114 [==============================] - 4s 42us/step - loss: 1.3425 - mean_squared_error: 5.1399e-04 - val_loss: 1.2312 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 9/20\n",
      "85114/85114 [==============================] - 4s 43us/step - loss: 1.1322 - mean_squared_error: 5.1399e-04 - val_loss: 1.0384 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 10/20\n",
      "85114/85114 [==============================] - 4s 43us/step - loss: 0.9549 - mean_squared_error: 5.1399e-04 - val_loss: 0.8758 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 11/20\n",
      "85114/85114 [==============================] - 4s 42us/step - loss: 0.8054 - mean_squared_error: 5.1399e-04 - val_loss: 0.7387 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 12/20\n",
      "85114/85114 [==============================] - 4s 43us/step - loss: 0.6793 - mean_squared_error: 5.1399e-04 - val_loss: 0.6230 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 13/20\n",
      "85114/85114 [==============================] - 4s 42us/step - loss: 0.5729 - mean_squared_error: 5.1399e-04 - val_loss: 0.5255 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 14/20\n",
      "85114/85114 [==============================] - 4s 46us/step - loss: 0.4832 - mean_squared_error: 5.1399e-04 - val_loss: 0.4433 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 15/20\n",
      "85114/85114 [==============================] - 4s 49us/step - loss: 0.4076 - mean_squared_error: 5.1399e-04 - val_loss: 0.3739 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 16/20\n",
      "85114/85114 [==============================] - 8s 98us/step - loss: 0.3438 - mean_squared_error: 5.1399e-04 - val_loss: 0.3154 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 17/20\n",
      "85114/85114 [==============================] - 4s 45us/step - loss: 0.2900 - mean_squared_error: 5.1399e-04 - val_loss: 0.2661 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 18/20\n",
      "85114/85114 [==============================] - 4s 45us/step - loss: 0.2447 - mean_squared_error: 5.1399e-04 - val_loss: 0.2245 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 19/20\n",
      "85114/85114 [==============================] - 4s 45us/step - loss: 0.2064 - mean_squared_error: 5.1399e-04 - val_loss: 0.1894 - val_mean_squared_error: 6.4839e-04\n",
      "Epoch 20/20\n",
      "85114/85114 [==============================] - 4s 44us/step - loss: 0.1741 - mean_squared_error: 5.1399e-04 - val_loss: 0.1599 - val_mean_squared_error: 6.4839e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_tf, y_train, epochs=20, batch_size=200,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89592993e-03, 0.00000000e+00, 2.30808861e-03, ...,\n",
       "       0.00000000e+00, 2.26687275e-04, 2.06079341e-05])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
